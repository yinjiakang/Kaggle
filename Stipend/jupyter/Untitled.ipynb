{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run cv: round: 500 folds: 5\n",
      "[0]\ttrain-merror:0.141824+0.0024545\ttest-merror:0.14543+0.00930825\n",
      "[20]\ttrain-merror:0.143087+0.00220039\ttest-merror:0.143317+0.00891172\n",
      "[40]\ttrain-merror:0.142421+0.00210571\ttest-merror:0.143408+0.00908232\n",
      "[60]\ttrain-merror:0.13994+0.00199651\ttest-merror:0.1435+0.0090227\n",
      "[80]\ttrain-merror:0.133969+0.00265211\ttest-merror:0.144235+0.0085787\n",
      "[100]\ttrain-merror:0.124483+0.00332831\ttest-merror:0.144419+0.00875713\n",
      "[120]\ttrain-merror:0.113918+0.00334809\ttest-merror:0.144878+0.00856718\n",
      "[140]\ttrain-merror:0.103009+0.00372836\ttest-merror:0.145521+0.00904536\n",
      "[160]\ttrain-merror:0.0905836+0.00346526\ttest-merror:0.14644+0.00893248\n",
      "[180]\ttrain-merror:0.0782038+0.00198643\ttest-merror:0.147083+0.00898919\n",
      "[200]\ttrain-merror:0.0659624+0.00185231\ttest-merror:0.147083+0.00888999\n",
      "[220]\ttrain-merror:0.0533534+0.00161358\ttest-merror:0.147634+0.0099481\n",
      "[240]\ttrain-merror:0.042926+0.0012858\ttest-merror:0.148094+0.0099992\n",
      "[260]\ttrain-merror:0.0329352+0.00144046\ttest-merror:0.148829+0.00949398\n",
      "[280]\ttrain-merror:0.0248046+0.000921251\ttest-merror:0.148737+0.00971136\n",
      "[300]\ttrain-merror:0.0183508+0.000613635\ttest-merror:0.149196+0.0104521\n",
      "[320]\ttrain-merror:0.0128388+0.00105091\ttest-merror:0.148553+0.0102863\n",
      "[340]\ttrain-merror:0.0089574+0.000924391\ttest-merror:0.148645+0.0105013\n",
      "[360]\ttrain-merror:0.0060174+0.000836545\ttest-merror:0.149104+0.0101456\n",
      "[380]\ttrain-merror:0.0043636+0.000538417\ttest-merror:0.149196+0.00964569\n",
      "[400]\ttrain-merror:0.0027102+0.000295977\ttest-merror:0.149104+0.00970771\n",
      "[420]\ttrain-merror:0.0017226+0.000217776\ttest-merror:0.149196+0.00985358\n",
      "[440]\ttrain-merror:0.0008268+0.000303179\ttest-merror:0.149196+0.00988801\n",
      "[460]\ttrain-merror:0.0004594+0.000205271\ttest-merror:0.14938+0.00959308\n",
      "[480]\ttrain-merror:0.000207+0.000134112\ttest-merror:0.149196+0.00955797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#train\\nwatchlist = [ (dtrain,\\'train\\')]\\nxgbmodel = xgb.train(xgb_param, dtrain, config[\\'round\\'], watchlist, verbose_eval = 20)\\npred = xgbmodel.predict(dtest)\\nintpred = [int(pred[i]) for i in range(len(pred))]\\nreal_pred = le.inverse_transform(intpred)\\n\\nresult = pd.DataFrame(columns = [\"studentid\",\"subsidy\"])\\nresult.studentid = test_id\\nresult.subsidy = real_pred\\nresult.subsidy = result.subsidy.apply(lambda x:int(x))\\n\\nprint (\\'1000--\\'+str(len(result[result.subsidy==1000])) + \\':741\\')\\nprint (\\'1500--\\'+str(len(result[result.subsidy==1500])) + \\':465\\')\\nprint (\\'2000--\\'+str(len(result[result.subsidy==2000])) + \\':354\\')\\n\\nresult.to_csv(\"../data/output/xgb_baseline.csv\",index=False)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "\n",
    "config = {\n",
    "    'round' : 500,\n",
    "    'random_seed' : 1218,\n",
    "    'fold' : 5\n",
    "}\n",
    "\n",
    "xgb_param = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective' : 'multi:softmax',\n",
    "    'num_class' : 4,\n",
    "    'early_stopping_rounds':100,\n",
    "\n",
    "    'max_depth' : 6,\n",
    "    'eta': 0.1,\n",
    "    'gamma' : 0.1,\n",
    "    'min_child_weight':3,\n",
    "\n",
    "    'subsample':0.7,    \n",
    "\n",
    "    'seed': config['random_seed'],\n",
    "    'nthread': 3,\n",
    "}\n",
    "\n",
    "\n",
    "#read subsidy\n",
    "train_subsidy = pd.read_csv('../data/train/subsidy_train.txt', header = None)\n",
    "train_subsidy.columns = ['ID', 'MONEY']\n",
    "test_subsidy = pd.read_csv('../data/test/studentID_test.txt', header = None)\n",
    "test_subsidy.columns = ['ID']\n",
    "test_subsidy['MONEY'] = np.nan\n",
    "train_test = pd.concat([train_subsidy, test_subsidy])\n",
    "train_test.to_csv(\"../data/input/train_test.csv\", index = False)\n",
    "\n",
    "#read card\n",
    "train_card = pd.read_csv('../data/train/card_train.txt', header = None)\n",
    "train_card.columns = ['ID', 'CARD_CAT', 'CARD_WHERE', 'CARD_HOW', 'CARD_TIME', 'CARD_SPEND', 'CARD_REMAINDER']\n",
    "test_card = pd.read_csv('../data/test/card_test.txt', header = None)\n",
    "test_card.columns = ['ID', 'CARD_CAT', 'CARD_WHERE', 'CARD_HOW', 'CARD_TIME', 'CARD_SPEND', 'CARD_REMAINDER']\n",
    "card_train_test = pd.concat([train_card,test_card])\n",
    "\n",
    "\n",
    "#process card data\n",
    "card = pd.DataFrame(card_train_test.groupby(['ID'])['CARD_CAT'].count())\n",
    "\n",
    "card['CARD_SPEND_SUM'] = card_train_test.groupby(['ID'])['CARD_SPEND'].sum()\n",
    "card['CARD_SPEND_MEAN'] = card_train_test.groupby(['ID'])['CARD_SPEND'].mean()\n",
    "card['CARD_SPEND_STD'] = card_train_test.groupby(['ID'])['CARD_SPEND'].max()\n",
    "card['CARD_SPEND_MEDIAN'] = card_train_test.groupby(['ID'])['CARD_SPEND'].median()\n",
    "\n",
    "card['CARD_REMAINDER_SUM'] = card_train_test.groupby(['ID'])['CARD_REMAINDER'].sum()\n",
    "card['CARD_REMAINDER_MEAN'] = card_train_test.groupby(['ID'])['CARD_REMAINDER'].mean()\n",
    "card['CARD_REMAINDER_STD'] = card_train_test.groupby(['ID'])['CARD_REMAINDER'].max()\n",
    "card['CARD_REMAINDER_MEDIAN'] = card_train_test.groupby(['ID'])['CARD_REMAINDER'].median()\n",
    "\n",
    "card.to_csv('../data/input/cardInfo.csv', index = True)\n",
    "card = pd.read_csv('../data/input/cardInfo.csv')\n",
    "train_test = pd.merge(train_test, card, how= 'left', on = 'ID')\n",
    "\n",
    "#read score\n",
    "train_score = pd.read_csv('../data/train/score_train.txt', header = None)\n",
    "train_score.columns = ['ID', 'COLLEGE', 'RANK']\n",
    "test_score = pd.read_csv('../data/test/score_test.txt', header = None)\n",
    "test_score.columns = ['ID', 'COLLEGE', 'RANK']\n",
    "train_test_score = pd.concat([train_score, test_score])\n",
    "\n",
    "score = pd.DataFrame(train_test_score.groupby(['COLLEGE'])['RANK'].max())\n",
    "score.to_csv('../data/input/collegeInfo.csv', index = True)\n",
    "score = pd.read_csv('../data/input/collegeInfo.csv')\n",
    "score.columns = ['COLLEGE', 'COLLEGE_STU_NUM']\n",
    "\n",
    "train_test_score = pd.merge(train_test_score, score, how='left', on='COLLEGE')\n",
    "train_test_score['SCORE'] = train_test_score['RANK'] / train_test_score['COLLEGE_STU_NUM']\n",
    "train_test = pd.merge(train_test, train_test_score, how = 'left', on = 'ID')\n",
    "\n",
    "\n",
    "#processing data for training\n",
    "train = train_test[train_test['MONEY'].notnull()].fillna(-1)\n",
    "test = train_test[train_test['MONEY'].isnull()].fillna(-1)\n",
    "\n",
    "train_id = train.ID\n",
    "test_id = test.ID\n",
    "\n",
    "drop_columns = ['ID', 'MONEY']\n",
    "train_features = train.drop(drop_columns, axis = 1)\n",
    "test_features = test.drop(drop_columns, axis = 1)\n",
    "\n",
    "train_label = train.MONEY\n",
    "train_id = train.ID\n",
    "test_id = test.ID\n",
    "\n",
    "#encoding label\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_encode_label = le.fit_transform(train_label)\n",
    "\n",
    "dtrain = xgb.DMatrix(train_features, label = train_encode_label)\n",
    "dtest = xgb.DMatrix(test_features)\n",
    "\n",
    "#for balance\n",
    "ssy0 = train[train['MONEY'] == 0]['ID'].count()\n",
    "ssy1000 = train[train['MONEY'] == 1000]['ID'].count()\n",
    "ssy1500 = train[train['MONEY'] == 1500]['ID'].count()\n",
    "ssy2000 = train[train['MONEY'] == 2000]['ID'].count()\n",
    "ssyNum = train['ID'].count()\n",
    "\n",
    "#cv\n",
    "print ('run cv: ' + 'round: ' + str(config['round']) + ' folds: ' + str(config['fold']))\n",
    "res = xgb.cv(xgb_param, dtrain, config['round'], nfold = config['fold'], verbose_eval = 20)\n",
    "\n",
    "\"\"\"#train\n",
    "watchlist = [ (dtrain,'train')]\n",
    "xgbmodel = xgb.train(xgb_param, dtrain, config['round'], watchlist, verbose_eval = 20)\n",
    "pred = xgbmodel.predict(dtest)\n",
    "intpred = [int(pred[i]) for i in range(len(pred))]\n",
    "real_pred = le.inverse_transform(intpred)\n",
    "\n",
    "result = pd.DataFrame(columns = [\"studentid\",\"subsidy\"])\n",
    "result.studentid = test_id\n",
    "result.subsidy = real_pred\n",
    "result.subsidy = result.subsidy.apply(lambda x:int(x))\n",
    "\n",
    "print ('1000--'+str(len(result[result.subsidy==1000])) + ':741')\n",
    "print ('1500--'+str(len(result[result.subsidy==1500])) + ':465')\n",
    "print ('2000--'+str(len(result[result.subsidy==2000])) + ':354')\n",
    "\n",
    "result.to_csv(\"../data/output/xgb_baseline.csv\",index=False)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.143225</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.143087</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-merror-mean  test-merror-std  train-merror-mean  train-merror-std\n",
       "3          0.143225         0.008975           0.143087          0.002347"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[res['test-merror-mean'] == res['test-merror-mean'].min() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.145430</td>\n",
       "      <td>0.009308</td>\n",
       "      <td>0.141824</td>\n",
       "      <td>0.002455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.143500</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>0.142582</td>\n",
       "      <td>0.002249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>0.142949</td>\n",
       "      <td>0.002494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.143225</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.143087</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.143179</td>\n",
       "      <td>0.002337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.143156</td>\n",
       "      <td>0.002320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.143087</td>\n",
       "      <td>0.002312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.143500</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.143156</td>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.143408</td>\n",
       "      <td>0.008818</td>\n",
       "      <td>0.143133</td>\n",
       "      <td>0.002309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.143500</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.143133</td>\n",
       "      <td>0.002225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.143500</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.143156</td>\n",
       "      <td>0.002248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.143133</td>\n",
       "      <td>0.002243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.143110</td>\n",
       "      <td>0.002244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.143408</td>\n",
       "      <td>0.009082</td>\n",
       "      <td>0.143087</td>\n",
       "      <td>0.002223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.143110</td>\n",
       "      <td>0.002244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.143500</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.143110</td>\n",
       "      <td>0.002244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.143500</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.143064</td>\n",
       "      <td>0.002288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.143408</td>\n",
       "      <td>0.008818</td>\n",
       "      <td>0.143156</td>\n",
       "      <td>0.002265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.143179</td>\n",
       "      <td>0.002222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.143110</td>\n",
       "      <td>0.002180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.143087</td>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.143087</td>\n",
       "      <td>0.002184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.143087</td>\n",
       "      <td>0.002248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.143087</td>\n",
       "      <td>0.002228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.143087</td>\n",
       "      <td>0.002188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.143408</td>\n",
       "      <td>0.009082</td>\n",
       "      <td>0.143018</td>\n",
       "      <td>0.002138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.142972</td>\n",
       "      <td>0.002159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.143317</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.142949</td>\n",
       "      <td>0.002202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.143408</td>\n",
       "      <td>0.009082</td>\n",
       "      <td>0.142995</td>\n",
       "      <td>0.002221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.143408</td>\n",
       "      <td>0.009082</td>\n",
       "      <td>0.142926</td>\n",
       "      <td>0.002226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.149288</td>\n",
       "      <td>0.009490</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.149104</td>\n",
       "      <td>0.009721</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.149104</td>\n",
       "      <td>0.009523</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.149104</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.149012</td>\n",
       "      <td>0.009541</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.149013</td>\n",
       "      <td>0.009363</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.148921</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.148829</td>\n",
       "      <td>0.009644</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.148645</td>\n",
       "      <td>0.009721</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.148829</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.149196</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.149472</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.149196</td>\n",
       "      <td>0.009041</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.149380</td>\n",
       "      <td>0.009398</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.149196</td>\n",
       "      <td>0.009492</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.149472</td>\n",
       "      <td>0.009443</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.149564</td>\n",
       "      <td>0.009514</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.149564</td>\n",
       "      <td>0.009466</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.149472</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.149472</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.149655</td>\n",
       "      <td>0.009438</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.149564</td>\n",
       "      <td>0.009721</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.149656</td>\n",
       "      <td>0.009664</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.149380</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.149380</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.149380</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.149472</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.149472</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.149472</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.149564</td>\n",
       "      <td>0.009708</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-merror-mean  test-merror-std  train-merror-mean  train-merror-std\n",
       "0            0.145430         0.009308           0.141824          0.002455\n",
       "1            0.143500         0.009065           0.142582          0.002249\n",
       "2            0.143317         0.009145           0.142949          0.002494\n",
       "3            0.143225         0.008975           0.143087          0.002347\n",
       "4            0.143317         0.008912           0.143179          0.002337\n",
       "5            0.143317         0.008912           0.143156          0.002320\n",
       "6            0.143317         0.008912           0.143087          0.002312\n",
       "7            0.143500         0.008728           0.143156          0.002200\n",
       "8            0.143408         0.008818           0.143133          0.002309\n",
       "9            0.143500         0.008728           0.143133          0.002225\n",
       "10           0.143500         0.008990           0.143156          0.002248\n",
       "11           0.143317         0.008912           0.143133          0.002243\n",
       "12           0.143317         0.008912           0.143110          0.002244\n",
       "13           0.143408         0.009082           0.143087          0.002223\n",
       "14           0.143317         0.008912           0.143110          0.002244\n",
       "15           0.143500         0.008990           0.143110          0.002244\n",
       "16           0.143500         0.008990           0.143064          0.002288\n",
       "17           0.143408         0.008818           0.143156          0.002265\n",
       "18           0.143317         0.008912           0.143179          0.002222\n",
       "19           0.143317         0.008912           0.143110          0.002180\n",
       "20           0.143317         0.008912           0.143087          0.002200\n",
       "21           0.143317         0.008912           0.143087          0.002184\n",
       "22           0.143317         0.008912           0.143087          0.002248\n",
       "23           0.143317         0.008912           0.143087          0.002228\n",
       "24           0.143317         0.008912           0.143087          0.002188\n",
       "25           0.143408         0.009082           0.143018          0.002138\n",
       "26           0.143317         0.008912           0.142972          0.002159\n",
       "27           0.143317         0.008912           0.142949          0.002202\n",
       "28           0.143408         0.009082           0.142995          0.002221\n",
       "29           0.143408         0.009082           0.142926          0.002226\n",
       "..                ...              ...                ...               ...\n",
       "470          0.149288         0.009490           0.000368          0.000134\n",
       "471          0.149104         0.009721           0.000322          0.000134\n",
       "472          0.149104         0.009523           0.000276          0.000156\n",
       "473          0.149104         0.009515           0.000276          0.000156\n",
       "474          0.149012         0.009541           0.000253          0.000134\n",
       "475          0.149013         0.009363           0.000253          0.000134\n",
       "476          0.148921         0.009411           0.000276          0.000156\n",
       "477          0.148829         0.009644           0.000230          0.000162\n",
       "478          0.148645         0.009721           0.000207          0.000134\n",
       "479          0.148829         0.009675           0.000207          0.000134\n",
       "480          0.149196         0.009558           0.000207          0.000134\n",
       "481          0.149472         0.009381           0.000207          0.000134\n",
       "482          0.149196         0.009041           0.000230          0.000126\n",
       "483          0.149380         0.009398           0.000184          0.000117\n",
       "484          0.149196         0.009492           0.000184          0.000117\n",
       "485          0.149472         0.009443           0.000207          0.000113\n",
       "486          0.149564         0.009514           0.000184          0.000117\n",
       "487          0.149564         0.009466           0.000184          0.000117\n",
       "488          0.149472         0.009625           0.000184          0.000117\n",
       "489          0.149472         0.009625           0.000184          0.000117\n",
       "490          0.149655         0.009438           0.000184          0.000117\n",
       "491          0.149564         0.009721           0.000207          0.000113\n",
       "492          0.149656         0.009664           0.000207          0.000113\n",
       "493          0.149380         0.009602           0.000184          0.000092\n",
       "494          0.149380         0.010095           0.000184          0.000117\n",
       "495          0.149380         0.010091           0.000161          0.000092\n",
       "496          0.149472         0.009782           0.000161          0.000092\n",
       "497          0.149472         0.009777           0.000161          0.000117\n",
       "498          0.149472         0.009777           0.000138          0.000086\n",
       "499          0.149564         0.009708           0.000115          0.000073\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
